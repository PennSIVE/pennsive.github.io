<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.319">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>PennSIVE Wiki – cluster_intro</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PennSIVE Wiki</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html" rel="" target="">
 <span class="menu-text">Welcome</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://github.com/pennsive/pennsive.github.io">
            Source Code
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://github.com/PennSIVE/pennsive.github.io/issues/new">
            Report a Bug
            </a>
          </li>
      </ul>
    </div>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./cluster_intro.html">Cluster Computing</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./environments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Environment setup</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./projects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project setup</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./heudiconv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dicom Conversion</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./flywheel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Flywheel</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pipelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PennSIVE pipelines</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reproducibility</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./workflows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nipype workflows</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gpu-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GPU Computing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rpackages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R Packages</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cluster_intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Cluster Computing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./contributing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributing to this Wiki</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#cluster-computing" id="toc-cluster-computing" class="nav-link active" data-scroll-target="#cluster-computing">Cluster Computing</a></li>
  <li><a href="#logging-in" id="toc-logging-in" class="nav-link" data-scroll-target="#logging-in">Logging In</a></li>
  <li><a href="#file-explorer" id="toc-file-explorer" class="nav-link" data-scroll-target="#file-explorer">File Explorer</a>
  <ul class="collapse">
  <li><a href="#winscp" id="toc-winscp" class="nav-link" data-scroll-target="#winscp">WinSCP</a></li>
  <li><a href="#fetch" id="toc-fetch" class="nav-link" data-scroll-target="#fetch">Fetch</a></li>
  </ul></li>
  <li><a href="#navigating-the-terminal" id="toc-navigating-the-terminal" class="nav-link" data-scroll-target="#navigating-the-terminal">Navigating the Terminal</a></li>
  <li><a href="#submitting-jobs" id="toc-submitting-jobs" class="nav-link" data-scroll-target="#submitting-jobs">Submitting Jobs</a>
  <ul class="collapse">
  <li><a href="#interactive-jobs" id="toc-interactive-jobs" class="nav-link" data-scroll-target="#interactive-jobs">Interactive Jobs</a></li>
  <li><a href="#batch-jobs" id="toc-batch-jobs" class="nav-link" data-scroll-target="#batch-jobs">Batch Jobs</a>
  <ul class="collapse">
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example">Example</a></li>
  </ul></li>
  <li><a href="#array-jobs" id="toc-array-jobs" class="nav-link" data-scroll-target="#array-jobs">Array Jobs</a></li>
  </ul></li>
  <li><a href="#canceling-a-job" id="toc-canceling-a-job" class="nav-link" data-scroll-target="#canceling-a-job">Canceling a job</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="cluster-computing" class="level1">
<h1>Cluster Computing</h1>
<p><em>Cluster computing</em> used here refers to the use of remote resources for a computation. This contrasts with <em>local computing</em>, the use of a resource such as a personal or laptop/desktop for a computation. An example could be running a script in a programming language (R, Python, etc.); this could be down with either computing type. What benefits are there in using these remote resources? Doing so can provide the following advantages over local computing:</p>
<ul>
<li>Have multiple computations running simultaneously</li>
<li>Queue computations to run automatically</li>
<li>Use more powerful computational resources (more memory, faster CPU, accessing GPUs, etc.)</li>
</ul>
<p>which can make your computations much more efficient, and sometimes feasible when local resources are not sufficient. This can conceptualized with the following diagram:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/cluster_intro_diagram.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">www.esds.co.in</figcaption><p></p>
</figure>
</div>
<p>where your instructions for the computations are sent to a central remote computer from your local computer, <em>node</em>, which then controls how these are sent out to be completed by the other nodes.</p>
<p>In this wiki entry, we will go over the basics of how cluster computing works with the resources available at Penn and how to interface with these resources on a fundamental level. More efficient and powerful ways are covered in the “Advanced Cluster Practices” wiki. Both wiki entries will discuss all of this topics in the context of the <code>takim</code> cluster on PMACS, though there are other clusters which you may have access to which operate slightly differently (e.g.&nbsp;CUBIC). Examples here are down in Windows, but Mac or Linux would be very similar.</p>
</section>
<section id="logging-in" class="level1">
<h1>Logging In</h1>
<p>First, to access the <code>takim</code> cluster you must log-in like you would for any computer. This is done using the <strong>Command Line/Prompt</strong> in Windows or Mac. To log-in to <code>takim</code>, you must first be logged into the PMACS VPN using the <strong>Pulse Secure</strong> app. Once you have logged in, you can use</p>
<p><code>ssh pennkey@takim</code></p>
<p>where <code>pennkey</code> is your PennKey ID. The command line will then ask for your PennKey password.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/log_in.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Log-in to takim</figcaption><p></p>
</figure>
</div>
<p>You command line should show <code>pennkey@takim ~$</code> with a blinking bar. This means you are logged-in and directly interfacing with a central node. Using the command line, you can now type instructions to this node, a Unix computer, as you would with a usual command line interface. Before we go over some basic Unix instructions, let’s talk about file access on the cluster.</p>
</section>
<section id="file-explorer" class="level1">
<h1>File Explorer</h1>
<p>Uploading, downloading, and editing files and interfacing between these files on your local and cluster computing resources can be done through the command line or a visual <strong>file explorer</strong> app. Using a file explorer is much easier since it as a Graphical User Interface (GUI) and mimics how you manage files on your local computer. The file explorer you use is dependant on the operating system (OS) of your local computer: <strong>WinSCP</strong> for Windows users and <strong>Fetch</strong> for Mac users are good options. We discuss both of them here:</p>
<section id="winscp" class="level2">
<h2 class="anchored" data-anchor-id="winscp">WinSCP</h2>
<p>After downloading and installing WinSCP, you again need to sign-in to the cluster, but this time through WinSCP itself. First select <code>New Session</code> in the upper-left corner, and then select <code>New Site</code> in the newly opened window. Here you specify the details of the cluster, including your log-in info like before. Click <code>Save</code> and then <code>Log-in</code> in this window to log-in to the cluster in WinSCP.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/winscp_login.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">WinSCP log-in</figcaption><p></p>
</figure>
</div>
<p>The window will disappear and you will see two windows; on the left is a file explorer for your local computer and on the right is a file explorer for your cluster directories.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/winscp_explorer.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">WinSCP Interface</figcaption><p></p>
</figure>
</div>
<p>You can then easily do various tasks such as create new and edit folders, drag and drop folders and files between the two explorers, search for files and folders, etc.</p>
</section>
<section id="fetch" class="level2">
<h2 class="anchored" data-anchor-id="fetch">Fetch</h2>
<p>On Mac, a good file explorer program is Fetch, which can downloaded at https://fetchsoftworks.com/. It is free to use for educational licenses, so members of Penn and other university can use it for free, otherwise you would have to pay. After installing Fetch and opening the program, a window should pop-up where you specify the server you wish to connect to. If one does not pop-up, you can select <code>File</code> and <code>New connection</code> at the top of the Fetch application. The window should look like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/fetch_log_in_empty.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Fetch New Connection</figcaption><p></p>
</figure>
</div>
<p>where you then fill-in your cluster information (username, password, etc.). Here is an example of a filled-in log-in to the <code>takim</code> cluster:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/fetch_log_in_fill.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Fetch New Connection</figcaption><p></p>
</figure>
</div>
<p>You can use the <code>heart</code> icon to save the server address as a favorite to easily access again, as well as the <code>keychain</code> to save passwords. Now that you are logged in, a file directory interface for the cluster will pop up, with the folder displayed being the one specified in the log-in by <code>initial folder</code>, usually you <code>home</code> directory on the server. An example on <code>takim</code>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/fetch_directory_view.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Fetch New Connection</figcaption><p></p>
</figure>
</div>
<p>From this window, you can open up folders on the server by clicking on them, navigate the folder structure on the server using the <code>Path</code> icon, and upload/download files to and from the cluster by drag-and-drop as you would usually do with a file explorer interface.</p>
</section>
</section>
<section id="navigating-the-terminal" class="level1">
<h1>Navigating the Terminal</h1>
<p>Let’s go back to the command line/prompt/terminal from before which we use to send instructions to the cluster after logging-in. Again, this is a Unix-based computer, so we can use the usual Unix commands to send instructions through the command line. A few basic ones are:</p>
<ul>
<li><code>cd</code>: Move working directory to new place (e.g.&nbsp;<code>cd Documents</code>)</li>
<li><code>ls</code>: View contents of current working directory</li>
<li><code>pwd</code>: Print current working directory</li>
<li><code>w</code>: Prints out infomation on who is logged-in to the cluster</li>
</ul>
<p>There are also commands for creating folders, removing files and folders, copying files and folders, etc. You can view them and others <a href="https://mally.stanford.edu/~sr/computing/basic-unix.html">here</a>, though using the file explorer for these tasks is easier and less error-prone. Each command is done one-by-one, with <code>Enter</code> submitting the command. For example, let’s use <code>pwd</code> in my session:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/cmd_line_example.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Command Line Example</figcaption><p></p>
</figure>
</div>
<p>which states that by default I am in my <code>home</code> directory on <code>takim</code>. A main task you will use the command line for is submitting computations to be done by the cluster computers, which we now discuss.</p>
</section>
<section id="submitting-jobs" class="level1">
<h1>Submitting Jobs</h1>
<p><strong>Job</strong> refers to a set of computations which you send to the cluster computer to carry out. There a variety of options you have when organizing these instructions in terms of how these computations are distributed amongst the different nodes on the cluster, how output and status reports on these computations are saved, etc. We discuss three types of jobs which are most useful: 1) <strong>batch jobs</strong>, 2) <strong>array jobs</strong>, 3) <strong>interactive jobs</strong>. Batch jobs run a single set of computations in sequence: i.e., only one node is given all of the computations to complete. Array jobs all you to <strong>parrallel</strong> the computations across multiple nodes automatically through the job submission process, allowing for multiple computations to be down by multiple nodes at once. This can be very powerful in efficiently completing a large amount of computations which otherwise not be feasible. An interactive job all you to submit computations on-the-fly like you do when programming on your local computer. This contrasts with batch and array jobs which are not interactive: you send out a set of instructions, central node schedules these instructions to be completed and the entire set is attempted at once.</p>
<p>We first discuss interactive jobs in the context of R programming as they are the most intutive and then move toward the other two. While we discuss using the command line to complete these jobs, it is best done with the use of <strong>Visual Studio Code</strong>, which we discuss in the second set of cluster wikis.</p>
<section id="interactive-jobs" class="level2">
<h2 class="anchored" data-anchor-id="interactive-jobs">Interactive Jobs</h2>
<p>As a motivating example of an interactive job, suppose to do some R programming on a cluster computer. While this might not seem useful since you can program instead on your local computer, interactive jobs can be used to 1) test code on the cluster to make sure it works as expected when you submit the whole set of computations to the cluster and 2) allows to program on-the-fly with a computer likely more powerful then your local computer. You use other programming languages in this way, such as Python, but here we focus on R.</p>
<p>First, we have to start R on the cluster after logging-in. To use, just type in the command <code>R</code> and hit <code>Enter</code> in the command line:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/r_session.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Starting a R Session</figcaption><p></p>
</figure>
</div>
<p>This will open up a session of R on an available cluster node, which we can operate as you usually would with a R terminal. Available nodes are ones which are currently not doing any computations requested by you or other users. The command <code>R</code> will start a default R session, i.e.&nbsp;a version of R denoted as the “default” in the cluster. If you want to use another version of R installed on thr cluster, you would need the corresponding command. If you want to see what software is available and loaded on the cluster (for example, what versions of R are available), use the command <code>module list</code>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/module_list.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Module List Command</figcaption><p></p>
</figure>
</div>
<p>Working in an interactive R session is identical to running R througn your command line on your local computer or using the R terminal panel in RStudio. To use a GUI-based interface with R interactive R job, see the second set of cluster wikis which discusses Visual Studio Code.</p>
<p>Now that we have our R session running, we are going to have to deal with 1) working directories and 2) <strong>R packages</strong>. The default working directory is always your <code>home</code> directory, which you can change using <code>setwd</code> in your R session per-usual. This will let you access files and paths in your R session on the cluster in reference to the working directory with relative path names (or can use absolute path names). R packages are more complicated. By default, a set of R packages has been installed to a central directory on <code>takim</code> which everyone has read access to (can load the packages) but not write access to (cannot install packages). We can use <code>.libPaths()</code> to view this folder’s name and <code>installed. packages()</code> to view which packages these are. It’s a lot of packages, so don’t submit this command only! We look at the first 10 packages by name:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/libpaths.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Module List Command</figcaption><p></p>
</figure>
</div>
<p>What if a package you would like is not installed here? The default library where packages are which users across the cluster can use is not writeable by users. So we need to create our own folder to install packages to and read in when we use R. This is easiest in your File Explorer program (WinSCP or Fetch). For example, we can create a folder in our default <code>home</code> directory on the <code>takim</code> cluster, which only you have read/write access to. For me, the folder’s path is <code>/home/kmdono02/r_packages/</code> where <code>kmdono02</code> would be replaced with your username, though you can choose in path you would like. You’ll see below I have a number of installed packages in this folder.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/r_pkg_directory.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">R Package Directory</figcaption><p></p>
</figure>
</div>
<p>When running R on the cluster, we then have to point to this directory as a <code>libPath</code> so that it knows to look here for a package we may want to load. This can be using the command <code>.libPaths("/home/kmdono02/r_packages/")</code> in your R session/script. We can use the usual <code>library()</code> command in R to load a package installed in the default and added R <code>libPaths</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/libpaths_edit.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">.LibPaths() Command</figcaption><p></p>
</figure>
</div>
<p>Now that we have our packages all set up and know how to set our working direcotry, as well as referencing files and folders using absolute and relative path name, we are all set to use the R interactive session on the cluster just like we would if we were running R on our local computer through the R console/terminal. However, we usually don’t rin R through the terminal on our local computer as it is quite cumbersome. Instead we usually use an IDE which is more graphical/user-friendly like RStudio. Luckily we can also use IDE’s to run an R interactive session on the cluster! Two options are RStudio Server and Visual Studio Code (VSCode). VSCode is easier to set up, so we cover how to use it on the cluster in the <strong>advanced cluster wiki</strong>.</p>
</section>
<section id="batch-jobs" class="level2">
<h2 class="anchored" data-anchor-id="batch-jobs">Batch Jobs</h2>
<p>While interactive jobs are very useful, batch jobs in which you send a set of instructions to be carried out remotely by the cluster nodes are a powerful tool and provide the main benefit of cluster computing. These jobs consist of two files: 1) <code>sh</code> file and 2) programming script (<code>R</code> script, <code>Python</code> script). The <code>sh</code> file(s) provide the details about <strong>how</strong> the job is carried out and then the script provides the computations you want to be done by the nodes. For example, suppose you want to run a linear regression model in R on the cluster? The <code>sh</code> file could provide instructions such as what programming script to run, where to store output on the status of the job from the node, to run a batch job vs array job, etc. In the regression example, suppose we have our R script to run the model in the folder <code>/home/kmdono02/r_scripts/</code>. Then, our <code>sh</code> file could be</p>
<p><code>cd /home/kmdono02/r_scripts/</code> <code>exec R CMD BATCH  --no-save --no-restore run_model.R  ../batch_output/log.out</code></p>
<p>The <code>sh</code> file tells the cluster node two things. First, set the working directory to the folder where the script is stored. Then, run the R script <code>run_model.R</code> in a R session on the node and print the log file to the folder <code>batch_output</code> in the directory <code>/home/kmdono02</code>, with the log file named <code>log.out</code>. The pieces <code>--no-save</code> and <code>--no-restore</code> are just options we can specify to the <code>R CMD BATCH</code> command. Note that these are all just command line commands, equivalent to if we typed these exact lines when we opend the command line in the beginning to interact with the cluster. Putting them in an <code>sh</code> file/script allows us to include a bunch of commands and submit them at once compared to submit each one-by-one, making the process more efficient. These files can also be used to include additional options as hinted at above, but will discuss in the <strong>advanced cluster wiki</strong>.</p>
<p>Now that the instructions for our job are all ready, the next step is to actually submit the job to the cluster to be completed. In our <code>sh</code> file-based setup, that means to submit the <code>sh</code> file to the cluster to be completed. For any job, the process is the following:</p>
<ol type="1">
<li>Submit job to central node. Job is given a number as an ID in the system, with system specifications provided for the job (max memory, number of CPUs, etc.)</li>
<li>Job is placed in <strong>scheduler</strong>, controlled by the central node. On <code>takim</code>, the scheduler is called <strong>LSF</strong> (though others exist such as <strong>SLURM</strong>)</li>
<li>Scheduler handles queue of jobs from all users on cluster, depending on order of submission decides which to start</li>
<li>Your job is next on the queue, central node submits to node to run job</li>
</ol>
<p>We go through each process using the linear regression example in R, called <code>run_model.R</code>.</p>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>Let’s consider the following R script:</p>
<pre><code>library(tidyverse)

# Suspend running commands to pause script to see it in scheduler (since it runs very fast!)
Sys.sleep(30)

# Run model on iris dataset
model &lt;- lm(Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length, data = iris)

# Store output as txt file
sink(file = "/home/kmdono02/cluster_examples/batch/r_output/model_summary.txt")
print(summary(model))
sink()</code></pre>
<p>Then, we can specifcy the <code>sh</code> file for instructions on how the cluster should complete this code, called <code>batch.sh</code>:</p>
<pre><code>#BSUB -o /home/kmdono02/cluster_examples/batch/logs/run_model.out
#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model.err

cd /home/kmdono02/cluster_examples/batch/batch_scripts
exec R CMD BATCH --no-save --no-restore ../r_scripts/run_model.R  ../output/run_model.out</code></pre>
<p>This is similar to file from before, just with some filenames changed and two new lines at the beginning. The lines starting with <code>#BSUB</code> provide the additional instructions to the node for running this job. The options <code>-o</code> and <code>e</code> provide locations to store the output and error files on the LSF-side, which details infomation regarding the node(s) used to complete the job, any errors that occured, etc. To submit this file, we use the following commands in our Command Line after logging into the cluster:</p>
<pre><code>cd /home/kmdono02/cluster_examples/batch/batch_scripts
bsub &lt; batch.sh</code></pre>
<p>The workhorse function for the job submitting process is <code>bsub</code>, which is where you specify the file detailing the submission. The addition of <code>&lt;</code> enables <code>bsub</code> to “parse” your <code>sh</code> file for arguments labled <code>#BSUB</code>, which will automatically be included as options in the <code>bsub</code> command. We could have also removed those two lines from the <code>sh</code> file and included them directly in the <code>bsub</code> call:</p>
<pre><code>bsub -o /home/kmdono02/cluster_examples/batch/logs/run_model.out -e /home/kmdono02/cluster_examples/batch/logs/run_model.err sh batch.sh</code></pre>
<p>though the first way is what we use from here on in these wikis. What happens after we run <code>bsub</code>? Recall our job enters the queue. To see the status of jobs we have submitted or are currently running, we use thr <code>bjobs</code> command. Let’s call it after running <code>bsub</code> and see the output:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/bjobs_ex.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Viewing queue</figcaption><p></p>
</figure>
</div>
<p>As you can, it took a second after the job was submitted, but it shortly showed up to the queue under my username with a job ID and starting running immediatey. This meant there was an open node for my job right when I submitted it. In the event there is not such an opening, it will show with the status <code>PENDING</code>. Finally we can look at our folders to view our output. For <code>model_summary.txt</code>, we see the output we asked for R to print</p>
<pre><code>Call:
lm(formula = Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length, 
    data = iris)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.60959 -0.10134 -0.01089  0.09825  0.60685 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -0.24031    0.17837  -1.347     0.18    
Petal.Length  0.52408    0.02449  21.399  &lt; 2e-16 ***
Sepal.Width   0.22283    0.04894   4.553 1.10e-05 ***
Sepal.Length -0.20727    0.04751  -4.363 2.41e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.192 on 146 degrees of freedom
Multiple R-squared:  0.9379,    Adjusted R-squared:  0.9366 
F-statistic: 734.4 on 3 and 146 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>From <code>output/run_model.out</code>, we see everything from the R terminal for this script with a <code>proc.time()</code> call added:</p>
<pre><code>R version 4.2.2 (2022-10-31) -- "Innocent and Trusting"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

&gt; library(tidyverse)
 Attaching packages  tidyverse 1.3.2 
 ggplot2 3.4.0       purrr   1.0.0 
 tibble  3.1.8       dplyr   1.0.10
 tidyr   1.2.1       stringr 1.5.0 
 readr   2.1.3       forcats 0.5.2 
 Conflicts  tidyverse_conflicts() 
 dplyr::filter() masks stats::filter()
 dplyr::lag()    masks stats::lag()
&gt; 
&gt; # Suspend running commands to pause script to see it in scheduler (since it runs very fast!)
&gt; Sys.sleep(60)
&gt; 
&gt; # Run model on iris dataset
&gt; model &lt;- lm(Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length, data = iris)
&gt; 
&gt; # Store output as txt file
&gt; sink(file = "/home/kmdono02/cluster_examples/batch/r_output/model_summary.txt")
&gt; print(summary(model))
&gt; sink()
&gt; 
&gt; proc.time()
   user  system elapsed 
  3.487   0.451  64.499 </code></pre>
<p>and finally we have our logs. The error log file is empty since no error occured. File <code>logs/run_model.out</code> shows the cluster-related log:</p>
<pre><code>Sender: LSF System &lt;jszostek@pennsive03&gt;
Subject: Job 19258593: &lt;#BSUB -o /home/kmdono02/cluster_examples/batch/logs/run_model.out;#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model.err; cd /home/kmdono02/cluster_examples/batch/batch_scripts;exec R CMD BATCH --no-save --no-restore ../r_scripts/run_model.R  ../output/run_model.out&gt; in cluster &lt;PMACS-SCC&gt; Done

Job &lt;#BSUB -o /home/kmdono02/cluster_examples/batch/logs/run_model.out;#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model.err; cd /home/kmdono02/cluster_examples/batch/batch_scripts;exec R CMD BATCH --no-save --no-restore ../r_scripts/run_model.R  ../output/run_model.out&gt; was submitted from host &lt;takim&gt; by user &lt;kmdono02&gt; in cluster &lt;PMACS-SCC&gt; at Sun Feb 26 13:37:32 2023
Job was executed on host(s) &lt;pennsive03&gt;, in queue &lt;taki_normal&gt;, as user &lt;kmdono02&gt; in cluster &lt;PMACS-SCC&gt; at Sun Feb 26 13:37:33 2023
&lt;/home/kmdono02&gt; was used as the home directory.
&lt;/home/kmdono02/cluster_examples/batch/batch_scripts&gt; was used as the working directory.
Started at Sun Feb 26 13:37:33 2023
Terminated at Sun Feb 26 13:37:39 2023
Results reported at Sun Feb 26 13:37:39 2023

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -o /home/kmdono02/cluster_examples/batch/logs/run_model.out
#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model.err

cd /home/kmdono02/cluster_examples/batch/batch_scripts
exec R CMD BATCH --no-save --no-restore ../r_scripts/run_model.R  ../output/run_model.out
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3.47 sec.
    Max Memory :                                 59 MB
    Average Memory :                             59.00 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                6
    Run time :                                   5 sec.
    Turnaround time :                            7 sec.

The output (if any) follows:</code></pre>
<p>with a handy resource usage summary detailing time of computation, requested (if applicable) and used memory, etc. We have run our first batch job! This format is generalizable for all cases where you want to run a single R script one time. Make sure to specify <code>.libPaths()</code> in your R script if you are using user-installed packages. For running a <strong>Python</strong> script instead, everything is the same except the use of <code>exec R CMD BATCH</code>. Instead you replace this with <code>python ../py_scripts/run_model.py</code> for example. Requesting an output file from the Python terminal like we did here is a little more complicated as a it must be done in the Python script itself, which we cover in the <strong>advanced cluster wiki</strong>.</p>
</section>
</section>
<section id="array-jobs" class="level2">
<h2 class="anchored" data-anchor-id="array-jobs">Array Jobs</h2>
<p>The last type of job that we cover is an <strong>array job</strong>. This allows you to submit a sequence of batch jobs simulatenously, which are similar but change in one or more arguments/indices. These jobs are sent to the scheduler at once after submitting one array job, handled like a set of batch jobs of the same size. For example, suppose you have a image processing pipeline to wish to run on an image from 10 subjects. You want to run the same pipeline on each subject, so the code to run on each subject is going to be the same except for reading and writing data based on the subject ID. Instead of writing 10 scripts or writing one script and then submitting 10 separate jobs where we manually specify the subject, can automate it with an array job.</p>
<p>The process is the same as with a batch job, in that we will a <code>bsub</code> call, an <code>sh</code> file containing instructions, and then probably some programming language script such as <code>R</code>. The difference is we now have to specify the indices of the array which constitute the array job in the <code>bsub</code> call and <code>sh</code> file. Suppose we want to run our batch job example (linear regression model), but run it on five different sets of data (<code>data_1.csv</code>, …, <code>data_5.csv</code>) where each dataset has outcome <code>y</code> and covariates <code>x1</code> to <code>x3</code> (the data sets are simulated from a corresponding linear regression model for illustration). For the <code>bsub</code> call, instead of</p>
<pre><code>cd /home/kmdono02/cluster_examples/batch/batch_scripts
bsub &lt; batch.sh</code></pre>
<p>we would need to call</p>
<pre><code>cd /home/kmdono02/cluster_examples/batch/batch_scripts
bsub &lt; -J "[1-5]" batch.sh</code></pre>
<p>in our cluster terminal. The use of <code>-J "[1-5]"</code> tells the scheduler to create an array job with indices 1 to 5. We can use other types of indices, such as <code>-J "[2,4]"</code> which will create an array job with only indices 2 and 4. The way these indices relate to what instructions are completed in your <code>sh</code> is that for each job in the array, the corresponding index becomes a <strong>Unix environment variable</strong> which you can reference inside of your job. This variable has the name <code>LSB_JOBINDEX</code>, which can you use in your R and Python scripts. However, you will also want to have some way to view logs related to each array job to view any errors or output from the cluster which is specific to that job in the array. Recall before we added in <code>#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model.err</code> for example to print out an error log for the submitted job. However, this was suboptimal since there is no <strong>job ID</strong> attached to it. We knew before what it was related to, since we were only running one <code>sh</code> file with the name <code>run_model</code>. Now that we have an array job which contains multiple jobs (5 for example), we need error logs for each one with a name to reference. Luckily this is very easy, and we have two options. First, recall each batch job receives a numeric ID once it has been submitted by the scheduler. This also becomes an environmental variable which we can access, labeled <code>LSB_JOBID</code>. We can also use the variable <code>%J</code> in our <code>sh</code> file and/or <code>bsub</code> commands to refer to the job ID before run. For example, we can replace the previous <code>#BSUB</code> line in our <code>batch.sh</code> file with <code>#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model_%J.err</code> to paste in the ID of the given batch job into the file name of that job’s error log and have it be written to our <code>log</code> directory to view. How does this relate to array jobs? Recall an array job is just a sequence of submitted batch job. Thus, each job in our array also gets a job ID to reference, which is contained in <code>LSB_JOBID</code> and <code>%J</code>. However, these IDs are long and not interpretable, what if we just want to refer to the index within our specific array job (job 1, job 2, etc.)? We just use <code>LSB_JOBINDEX</code> and <code>%l</code> respectively instead. We also add in <code>%J</code> or <code>%l</code> to the other <code>#BSUB</code> lines in our <code>sh</code> file, as well as our <code>exec R CMD BATCH</code> call when we specify the <code>Rout</code> filepath.</p>
<p>Let’s do the regression example with indices 1 through 5. We’ll specify a new <code>sh</code> file, call it <code>batch_array.sh</code>. This <code>sh</code> file will be</p>
<pre><code>#BSUB -o /home/kmdono02/cluster_examples/batch/logs/run_model_array_%l.out
#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model_array_%l.err

cd /home/kmdono02/cluster_examples/batch/batch_scripts
exec R CMD BATCH --no-save --no-restore ../r_scripts/run_model_array.R  ../output/run_model_array_$LSB_JOBINDEX.out</code></pre>
<p>where <code>run_model_array.R</code> will be our R script to run the array regression model example. We’ll simulate data within each array job to reflect one of the 5 datasets which we will run the model on, and control them by setting the seed. Thus, <code>run_model_array.R</code> is the following:</p>
<pre><code>library(tidyverse)

# Suspend running commands to pause script to see it in scheduler (since it runs very fast!)
Sys.sleep(30)

# Generate dataset
n &lt;- 100
i &lt;- as.numeric(Sys.getenv('LSB_JOBINDEX'))
set.seed(i)
x1 &lt;- rnorm(n); x2 &lt;- rnorm(n); x3 &lt;- rnorm(n); errors &lt;- rnorm(n, mean = 0, sd = 0.25)
y &lt;- 2*x1+3*x2+4*x3+errors
simdata &lt;- data.frame(x1, x2, x3, y)

# Run model
model &lt;- lm(y ~ x1 + x2 + x3, data = simdata)

# Store output as txt file
sink(file = paste0("/home/kmdono02/cluster_examples/batch/r_output/array_model_summary_", i, ".txt"))
print(summary(model))
sink()</code></pre>
<p>We have simulated data from a linear regression model, of sample size 100, with normally distributed errors with standard deviation 0.25 and 3 covariates of mean 0, with their regression parameters being 2, 3, and 4 respectively. We specify the seed with each dataset as the array index, using <code>Sys.getenv('LSB_JOBINDEX')</code>. This reads-in the environmental variable and then converts to it numeric (is character by default in R). We then fit the regression model and then print the output to our output folder with the index included for reference. We can combine this with the above <code>sh</code> file and below terminal commands to run our array job:</p>
<pre><code>cd /home/kmdono02/cluster_examples/batch/batch_scripts
bsub &lt; -J "[1-5]" batch_array.sh</code></pre>
<p>The queue is now the following after submitting our array jobs:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cluster_intro/array_queue.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Viewing queue</figcaption><p></p>
</figure>
</div>
<p>Let’s do so and look at the outputs. First, the output file for one of the arrays.</p>
<pre><code>Sender: LSF System &lt;jszostek@silver01&gt;
Subject: Job 19659506[1]: &lt;[1-5]&gt; in cluster &lt;PMACS-SCC&gt; Exited

Job &lt;[1-5]&gt; was submitted from host &lt;takim&gt; by user &lt;kmdono02&gt; in cluster &lt;PMACS-SCC&gt; at Wed Mar 22 17:46:27 2023
Job was executed on host(s) &lt;silver01&gt;, in queue &lt;taki_normal&gt;, as user &lt;kmdono02&gt; in cluster &lt;PMACS-SCC&gt; at Wed Mar 22 17:46:27 2023
&lt;/home/kmdono02&gt; was used as the home directory.
&lt;/home/kmdono02/cluster_examples/batch/batch_scripts&gt; was used as the working directory.
Started at Wed Mar 22 17:46:27 2023
Terminated at Wed Mar 22 17:47:02 2023
Results reported at Wed Mar 22 17:47:02 2023

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -o /home/kmdono02/cluster_examples/batch/logs/run_model_array_%I.out
#BSUB -e /home/kmdono02/cluster_examples/batch/logs/run_model_array_%I.err

cd /home/kmdono02/cluster_examples/batch/batch_scripts
exec R CMD BATCH --no-save --no-restore ../r_scripts/run_model_array.R  ../output/run_model_array_%I.out
------------------------------------------------------------

Exited with exit code 1.</code></pre>
<p>which is just a summary of what was submitted for the entire array job and what the exit code was, just like would happen for a batch job. Then we have 5 resource reports inside the file one for each of the arrays. The other array’s output files are the same: all resource usages for all arrays are stored in each. Then, you could just use <code>#BSUB -o /home/kmdono02/cluster_examples/batch/logs/run_model_array.out</code> to avoid the duplicate files. The R terminal output is stored in <code>../output/run_model_array_1.out</code> for the first array’s R terminal for example. Finally, we can view the output of the model fit requested by our R script in <code>/home/kmdono02/cluster_examples/batch/r_output/array_model_summary_1</code> for example, which is as expected. We have now run our first array job!</p>
</section>
</section>
<section id="canceling-a-job" class="level1">
<h1>Canceling a job</h1>
<p>To complete our introduction to cluster computing, we will cover one last scheduling command: <code>bkill</code>. This is how you tell the scheduler to cancel either a pending job that you submitted and am waiting in the queue to complete, or a currently running job. This is essentially to do when you are not longer interested in running a job to completion, as it clears up the queue for others to have their jobs run. To call a specific job, just call <code>bkill -b x</code> in your terminal where <code>x</code> is the job ID you wish to cancel. This ID can always be viewed in the <code>bjobs</code> output, as well as your <code>.out</code> file from the <code>bsub</code> submission. If you want to cancel all jobs under your cluster user name, just use <code>bkill -u username</code> where <code>username</code> is your user name.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In this wiki, went over the basic of running jobs on the <code>takim</code> cluster, particularly R and Python scripts. We covered to how to interact with the cluster using the terminal, handle file management using WinSCP and Fetch, as well as discussed a variety of job types and how to run them. In the next wiki, we will discuss some more advanced cluster techniques, generally centered around using <strong>Visual Studio Code</strong> to do all of your cluster work in one application.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>